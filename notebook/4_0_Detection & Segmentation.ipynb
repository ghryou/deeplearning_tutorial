{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard\n",
    "---\n",
    "<img src=\"https://github.com/lanpa/tensorboardX/raw/master/screenshots/Demo.gif\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "[Tensorboard Github](https://github.com/lanpa/tensorboardX)\n",
    "\n",
    "```\n",
    "docker exec -it pytorch bash\n",
    "/opt/conda/envs/pytorch-py$PYTHON_VERSION/bin/pip install tensorflow tensorboard\n",
    "tensorboard --logdir runs\n",
    "  > -i 옵션: 컨테이너가 STDIN을 오픈해서 유지하도록 지정\n",
    "  > -t 옵션: 컨테이너에 pesudo-tty(터미널)를 할당\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "resnet18 = models.resnet18(False)\n",
    "writer = SummaryWriter()\n",
    "sample_rate = 44100\n",
    "freqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n",
    "\n",
    "for n_iter in range(100):\n",
    "\n",
    "    dummy_s1 = torch.rand(1)\n",
    "    dummy_s2 = torch.rand(1)\n",
    "    # data grouping by `slash`\n",
    "    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)\n",
    "    writer.add_scalar('data/scalar2', dummy_s2[0], n_iter)\n",
    "\n",
    "    writer.add_scalars('data/scalar_group', {'xsinx': n_iter * np.sin(n_iter),\n",
    "                                             'xcosx': n_iter * np.cos(n_iter),\n",
    "                                             'arctanx': np.arctan(n_iter)}, n_iter)\n",
    "\n",
    "    dummy_img = torch.rand(32, 3, 64, 64)  # output from network\n",
    "    if n_iter % 10 == 0:\n",
    "        x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)\n",
    "        writer.add_image('Image', x, n_iter)\n",
    "\n",
    "        dummy_audio = torch.zeros(sample_rate * 2)\n",
    "        for i in range(x.size(0)):\n",
    "            # amplitude of sound should in [-1, 1]\n",
    "            dummy_audio[i] = np.cos(freqs[n_iter // 10] * np.pi * float(i) / float(sample_rate))\n",
    "        writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)\n",
    "\n",
    "        writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)\n",
    "\n",
    "        for name, param in resnet18.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)\n",
    "\n",
    "        # needs tensorboard 0.4RC or later\n",
    "        writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)\n",
    "\n",
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:100].float()\n",
    "label = dataset.test_labels[:100]\n",
    "\n",
    "features = images.view(100, 784)\n",
    "writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n",
    "\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization\n",
    "---\n",
    "### tSNE embedding\n",
    "<img src=\"http://cs231n.github.io/assets/cnnvis/tsne.jpeg\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture12-171031014710/95/cs231n-2017-lecture12-visualizing-and-understanding-9-638.jpg?cb=1509497509\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks in Computer Vision\n",
    "---\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-17-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "### Semantic Segmentation\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-21-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-23-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-25-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-27-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-38-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-43-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "### Classification & Localization\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-48-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-52-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "### Object Detection\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-54-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-56-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-61-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-62-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "#### Selective Search\n",
    "<img src=\"https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs11263-013-0620-5/MediaObjects/11263_2013_620_Fig2_HTML.jpg\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "[Selective Search 설명, 라온피플](https://m.blog.naver.com/laonple/220918802749)\n",
    "\n",
    "[OpenCV Selective Search Tutorial](https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/)\n",
    "\n",
    "#### R-CNN (Region based CNN)\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-68-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-69-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "#### Fast R-CNN\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-75-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-78-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "#### Faster R-CNN\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-81-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "#### Yolo (You Look Only Once)\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-84-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<h3><center>\n",
    "    <a href=\"http://www.youtube.com/watch?v=VOC3huqHrss\">Yolo v2</a>\n",
    "</center></h3>\n",
    "\n",
    "#### Image Captioning\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-86-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "#### Instance Segmentation\n",
    "<img src=\"https://image.slidesharecdn.com/cs231n2017lecture11-171030090644/95/cs231n-2017-lecture11-detection-and-segmentation-91-638.jpg?cb=1509354489\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2017/06/1birpf-ogjxarqf5lxi17jw.png?w=541&h=353\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "<h3><center>\n",
    "    <a href=\"http://www.youtube.com/watch?v=s8Ui_kV9dhw\">YOLO v2 vs YOLO v3 vs Mask RCNN vs Deeplab Xception</a>\n",
    "</center></h3>\n",
    "\n",
    "### Reference\n",
    "\n",
    "[R-CNN - Region-Based Convolutional Networks for Accurate Object Detection and Segmentation](https://ieeexplore.ieee.org/document/7112511/)\n",
    "\n",
    "[Fast R-CNN](https://arxiv.org/abs/1504.08083)\n",
    "\n",
    "[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497)\n",
    "\n",
    "[Yolo v1 - You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)\n",
    "\n",
    "[Yolo v2 - YOLO9000: Better, Faster, Stronger](https://arxiv.org/pdf/1612.08242.pdf)\n",
    "\n",
    "[Yolo v3 - YOLOv3: An Incremental Improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n",
    "\n",
    "[Mask R-CNN](https://arxiv.org/abs/1703.06870)\n",
    "\n",
    "[DeepLab v1 - \n",
    "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs](https://arxiv.org/abs/1412.7062)\n",
    "\n",
    "[DeepLab v2 - \n",
    "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/abs/1606.00915)\n",
    "\n",
    "[DeepLab v3 - \n",
    "Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
